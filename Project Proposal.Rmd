---
title: "How do library resources and infrastructure, financial investment and community characteristics predict the number of library visits per year?"
authors: "Isabella, Isla, Tala"
output: pdf_document
date: "2025-10-21"
margin: 2.5cm
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Introduction

For our project, we are interested in understanding how we can predict the annual number of visitors to a library by examining the effects of a wide range of predictors, such as the size of the physical and digital collection, programs offered and their geographic locations in proximity to urban areas. 

##Literature Summary

##Data Description
The dataset was obtained from the Public Libraries Survey (PLS) 2023, conducted annually by the Institute of Museum and Library Services (IMLS) in the United States. The PLS was originally designed to provide standardized national data on public library operations, such as visits, staffing, and expenditures, to support policy and service improvement. Data are collected through an annual national census survey of public libraries, self-reported by each library and verified by state data coordinators via a centralized web-based system.
#Data Description and Variable Summaries
```{r cleaning_code, echo=FALSE, eval=FALSE}
# loading and cleaning data 
library(tidyverse)
rawdata <- read.csv(file ="PLS_FY23_AE_pud23i.csv")
# extract relevant predictors
rawdata1 <- subset(as.data.frame(rawdata), select = c(VISITS, LIBNAME, HRS_OPEN, TOTSTAFF, TOTPHYS, EBOOK, TOTPRO, TOTATTEN, STAFFEXP, TOTEXPCO, TOTOPEXP, POPU_LSA, WEBVISIT, GPTERMS, LOCALE_MOD))
# merge categorical variables
library(dplyr)
rawdata1 <- rawdata1 %>%
  mutate(
    LOCALE_GROUP = case_when(
      LOCALE_MOD %in% c(11, 12, 13) ~ "Urban",
      LOCALE_MOD %in% c(21, 22, 23) ~ "Suburban",
      LOCALE_MOD %in% c(31, 32, 33) ~ "Town",
      LOCALE_MOD %in% c(41, 42, 43) ~ "Rural",
      TRUE ~ NA_character_  
    ),
    LOCALE_GROUP = factor(LOCALE_GROUP,
                          levels = c("Urban", "Suburban", "Town", "Rural"))
  )
table(rawdata1$LOCALE_GROUP)
str(rawdata1$LOCALE_GROUP)
sum(is.na(rawdata1$LOCALE_GROUP))
# Clean the data
# Step 1: Replace invalid codes (-1, -3, -9) with actual NA
rawdata1[rawdata1 == -1] <- NA
rawdata1[rawdata1 == -3] <- NA
rawdata1[rawdata1 == -9] <- NA
# Step 2: Check missing counts
colSums(is.na(rawdata1))
# Step 3: Remove rows containing NA
clean_data <- na.omit(rawdata1)
# Step 4: Confirm number of rows left
nrow(clean_data)
# characteristics 
library(dplyr)
library(tidyr)
library(ggplot2)
library(purrr)
cont_vars <- c("HRS_OPEN","TOTSTAFF","TOTPHYS","EBOOK","TOTPRO",
               "TOTATTEN","STAFFEXP","TOTEXPCO","TOTOPEXP",
               "POPU_LSA","WEBVISIT","GPTERMS","VISITS")
sum_table <- clean_data %>%
  select(all_of(cont_vars)) %>%
  pivot_longer(everything(), names_to = "variable", values_to = "value") %>%
  group_by(variable) %>%
  summarise(
    n = n(),
    min = min(value, na.rm=TRUE),
    q1 = quantile(value, 0.25, na.rm=TRUE),
    median = median(value, na.rm=TRUE),
    mean = mean(value, na.rm=TRUE),
    q3 = quantile(value, 0.75, na.rm=TRUE),
    max = max(value, na.rm=TRUE)
  )
print(sum_table)
table(clean_data$LOCALE_GROUP)
hist(clean_data$VISITS[clean_data$VISITS], breaks = 50,
     main = "Distribution of VISITS", xlab = "Number of Visits",
     col = "skyblue", border = "white") 
hist(clean_data$VISITS[clean_data$VISITS < 6e5], breaks = 50,
     main = "Distribution of VISITS (<600k)", xlab = "Number of Visits",
     col = "skyblue", border = "white")
boxplot(VISITS ~ LOCALE_GROUP, data = clean_data,
        main = "Visits by Location Type",
        xlab = "Locale", ylab = "Number of Visits", col = "lightblue")
ggplot(clean_data[clean_data$TOTPRO < 20000, ], 
       aes(x = TOTPRO, y = VISITS, color = LOCALE_GROUP)) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Programs vs. Visits by Locale (<20k Programs)", 
       x = "Programs Offered", y = "Visits", color = "Locale") +
  theme_minimal()
## Scatter plots for key numerical predictors vs VISITS
library(ggplot2)
# Define the key predictors
key_predictors <- c("TOTPRO", "STAFFEXP", "TOTPHYS")
# Loop through each predictor to make scatter plots
for (var in key_predictors) {
  p <- ggplot(clean_data, aes_string(x = var, y = "VISITS")) +
    geom_point(alpha = 0.3, color = "steelblue") +
    geom_smooth(method = "lm", se = FALSE, color = "darkred") +
    labs(
      title = paste("Relationship between", var, "and VISITS"),
      x = var,
      y = "Number of Visits"
    ) +
    theme_minimal(base_size = 13)
  print(p)
}
```
After merging categorical location codes and removing missing values, the final dataset includes 5,110 observations, 12 numerical predictors, and one categorical variable, LOCALE_GROUP，indicating the library’s location type  (Urban, Suburban, Town, Rural). The response variable, VISITS, measures annual physical library visits. As a continuous, non-negative variable roughly proportional to library scale, VISITS is suitable for linear regression analysis.
```{r table1, echo=FALSE}
library(knitr)
library(dplyr)
cont_vars <- c("HRS_OPEN","TOTSTAFF","TOTPHYS","EBOOK","TOTPRO",
               "TOTATTEN","STAFFEXP","TOTEXPCO","TOTOPEXP",
               "POPU_LSA","WEBVISIT","GPTERMS","VISITS")

sum_table <- clean_data %>%
  select(all_of(cont_vars)) %>%
  pivot_longer(everything(), names_to = "Variables", values_to = "value") %>%
  group_by(Variables) %>%
  summarise(
    Min = min(value, na.rm = TRUE),
    Max = max(value, na.rm = TRUE),
    Mean = round(mean(value, na.rm = TRUE), 2),
    `Interquartile Range` = round(IQR(value, na.rm = TRUE), 2),
    Median = median(value, na.rm = TRUE),
    `Standard deviation` = round(sd(value, na.rm = TRUE), 2)
  )

kable(sum_table, caption = "Table 1: Numerical summaries of the location and spread of the data")
``` 
Table 1 provides a numerical summary of all continuous predictors and response variable. Most numerical variables exhibit large ranges and standard deviations, suggesting substantial variation and the presence of outliers. In several variables, the mean exceeds the median, confirming right-skewness.
```{r fig1, echo=FALSE, fig.cap="Figure 1. Distribution of VISITS", fig.width=6, fig.height=4}
hist(clean_data$VISITS[clean_data$VISITS], breaks = 50,
     main = "Distribution of VISITS", xlab = "Number of Visits",
     col = "skyblue", border = "white")
```
Figure 1 shows the distribution of VISITS, which is highly right-skewed, indicating that most libraries have moderate visitor counts while a few receive extremely high visits.
```{r fig2, echo=FALSE, fig.cap="Figure 2. Visits by Location Type", fig.width=6, fig.height=4}
boxplot(VISITS ~ LOCALE_GROUP, data = clean_data,
        main = "Visits by Location Type",
        xlab = "Locale", ylab = "Number of Visits",
        col = "lightblue")
```
Figure 2 compares VISITS across location types, where Urban libraries have the highest medians and greatest variability, while Town and Rural libraries show lower and more consistent levels. This supports including LOCALE_GROUP  as a categorical predictor in the regression.
```{r fig3, echo=FALSE, fig.cap="Figure 3. Programs vs. Visits by Locale (<20k Programs)", fig.width=6, fig.height=4}
ggplot(clean_data[clean_data$TOTPRO < 20000, ], aes(x = TOTPRO, y = VISITS, color = LOCALE_GROUP)) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Programs Offered", y = "Visits", color = "Locale") +
  theme_minimal(base_size = 13)
```
Figure 3 presents the relationship between TOTPRO and VISITS by locale. The positive slopes across all groups indicate that offering more programs increases visits, with steeper slopes for Urban and Suburban libraries. This suggests an interaction effect between program and location, which will be incorporated into the preliminary regression model.

##Ethics Discussion

##Preliminary Model Results

##Analysis and Team Plan

##Bibliography

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:




